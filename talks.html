<ul style="margin-left: 2.5em;">
  <li><b>Offline Reinforcement Learning: Role of State Aggregation and Trajectory Data</b>
    <ol style="list-style-type: none; padding-top: 1pt;">
      <li>COLT, Edmonton, CA <span style="float: right;">Jun 2024</span></li>
      <li>Adaptive Learning in Complex Environments Workshop, TTIC, Chicago, USA <span style="float: right;">Apr 2024</span></li>
    </ol>
  </li>
  <li><b>Offline Data Enhanced On-Policy Policy Gradient</b>
    <ol style="list-style-type: none; padding-top: 1pt;">
      <li>Virtual RL Theory Seminar Series <span style="float: right;">Apr 2024</span></li>
      <li>CSA Theory Seminar, IISc Bangalore, India <span style="float: right;">Apr 2024</span></li>
    </ol>
  </li>
  <li><b>Ticketed Learning-Unlearning Schemes</b>
    <ol style="list-style-type: none; padding-top: 1pt;">
      <li>Max Planck Institute for Intelligent Systems, Tubingen, Germany <span style="float: right;">May 2024</span></li>
      <li>Conference on Learning Theory (COLT), Bangalore, India <span style="float: right;">Jul 2023</span></li>
      <li>CS Theory Seminar, Cornell University, Ithaca, USA <span style="float: right;">Nov 2023</span></li>
      <li>Annual Conference on Information Sciences and Systems (CISS), Princeton, USA <span style="float: right;">Mar 2024</span></li>
      <li>CS Theory Seminar, University of Pennsylvania, Philadelphia, USA <span style="float: right;">Mar 2024</span></li>
      <li>CSA Theory Seminar, IISc Bangalore, India <span style="float: right;">Apr 2024</span></li>
    </ol>
  </li>
  <li><b>Machine Unlearning: Algorithms, complexity, and new challenges</b>
    <ol style="list-style-type: none; padding-top: 1pt;">
      <li>Meta AI Research, USA <span style="float: right;">Apr 2023</span></li>
    </ol>
  </li>
  <li><b>Hybrid RL: Using Both Offline and Online Data Can Make RL Efficient</b>
    <ol style="list-style-type: none; padding-top: 1pt;">
      <li>ImprobableAI (Prof. Pulkit Agarwal's lab) meeting, MIT <span style="float: right;">Mar 2023</span></li>
    </ol>
  </li>
  <li><b>On the Complexity of Adversarial Decision Making</b>
    <ol style="list-style-type: none; padding-top: 1pt;">
      <li>Virtual RL Theory Seminar Series <span style="float: right;">Jul 2023</span></li>
      <li>BLISS Seminar, UC Berkeley, USA <span style="float: right;">Feb 2023</span></li>
      <li>Information Theory and Applications (ITA) Workshop, San Diego, USA <span style="float: right;">Feb 2023</span></li>
      <li>Theory Seminar, UCSD, San Diego, USA <span style="float: right;">Feb 2023</span></li>
      <li>Microsoft Research NYC, USA <span style="float: right;">Feb 2023</span></li>
      <li>ML Tea, Massachusetts Institute of Technology, USA <span style="float: right;">Apr 2023</span></li>
    </ol>
  </li>
  <li><b>When does SGD learn?</b>
    <ol style="list-style-type: none; padding-top: 1pt;">
      <li>Prof. Dan Roy's Lab, University of Toronto, CA <span style="float: right;">Oct 2022</span></li>
      <li>Mathematical Foundations of Deep Learning Reading Group, ETH Zurich <span style="float: right;">Nov 2022</span></li>
    </ol>
  </li>
  <li><b>Remember What You Want to Forget: Algorithms for Machine Unlearning</b>
    <ol style="list-style-type: none; padding-top: 1pt;">
      <li>AI Seminar, Cornell University <span style="float: right;">Feb 2022</span></li>
      <li>Prof. Jiantao Jiao's Lab, UC Berkeley <span style="float: right;">Aug 2021</span></li>
    </ol>
  </li>
  <li><b>SGD: The Role of Implicit Regularization, Batch-Size and Multiple Epochs</b>
    <ol style="list-style-type: none; padding-top: 1pt;">
      <li>Mathematical Foundations of Deep Learning Reading Group, ELLIS, ETH Zurich <span style="float: right;">May 2022</span></li>
      <li>Foundations of Data Science (FODS) Seminar, IISC (Tsinghua University), China <span style="float: right;">Apr 2022</span></li>
      <li>Collaboration on the Theoretical Foundations of Deep Learning (MODL) Monthly Meeting <span style="float: right;">Feb 2022</span></li>
      <li>Theory Seminar, Cornell University <span style="float: right;">May 2021</span></li>
      <li>Algorithms and Theory Seminar, University of Waterloo (CA) <span style="float: right;">Nov 2021</span></li>
      <li>Learning Theory Seminar, Google Research NY <span style="float: right;">Nov 2021</span></li>
    </ol>
  </li>
  <li><b>Agnostic Reinforcement Learning with Low-Rank MDPs and Rich Observations</b>
    <ol style="list-style-type: none; padding-top: 1pt;">
      <li>Artificial Intelligence (AI) Seminar, Cornell University <span style="float: right;">Mar 2021</span></li>
      <li>RL Reading Group, Cornell University <span style="float: right;">Jun 2021</span></li>
    </ol>
  </li>
  <li><b>Second-Order Information in Non-Convex Stochastic Optimization: Power and Limitations</b>
    <ol style="list-style-type: none; padding-top: 1pt;">
      <li>Highlights Beyond SIGMETRICS 2021, Beijing, China (Virtual) <span style="float: right;">Jun 2021</span></li>
      <li>Spotlight Talk, Annual ML Symposium, New York Academy of Sciences (NYAS) <span style="float: right;">Mar 2020</span></li>
      <li style="padding-left: 0.7em; color: red;">Best Talk Award, Honorable Mention</li>
      <li><a href="http://www.learningtheory.org/colt2020/virtual/papers/paper_345.html">Conference on Learning Theory</a> (COLT), Conference Talk <span style="float: right;">Jul 2020</span></li>
      <li>Learning Theory Seminar, Google NYC <span style="float: right;">Nov 2020</span></li>
      <li>Theory Tea, Cornell University <span style="float: right;">Nov 2020</span></li>
    </ol>
  </li>
  <li><b>The Complexity of Making the Gradient Small in Stochastic Convex Optimization</b>
    <ol style="list-style-type: none; padding-top: 1pt;">
      <li>Intern Talk Series, Google Research, New York <span style="float: right;">Jul 2019</span></li>
      <li>Theory Seminar, Cornell University <span style="float: right;">Nov 2019</span></li>
    </ol>
  </li>
  <li><b>Uniform Convergence of Gradients for Non-Convex Learning and Optimization</b>
    <ol style="list-style-type: none; padding-top: 1pt;">
      <li><a href="https://sites.google.com/view/icml2018nonconvex/">ICML Workshop on Modern Trends in Non-Convex Optimization for ML</a> <span style="float: right;">Jun 2018</span></li>
      <li>Annual ML Symposium, New York Academy of Sciences (NYAS) <span style="float: right;">Feb 2019</span></li>
    </ol>
  </li>
</ul>
